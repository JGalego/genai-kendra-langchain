{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76653ab1-e168-45c7-8c45-2208e37f71d0",
   "metadata": {},
   "source": [
    "## [GenAI applications on enterprise data with Amazon Kendra, LangChain and LLMs](https://aws.amazon.com/blogs/machine-learning/quickly-build-high-accuracy-generative-ai-applications-on-enterprise-data-using-amazon-kendra-langchain-and-large-language-models/)\n",
    "\n",
    "In this tutorial, we will demonstrate how to implement [Retrieval Augmented Generation](https://arxiv.org/abs/2005.11401) (RAG) workflows with the combined powers of [Amazon Kendra](https://aws.amazon.com/kendra/), [🦜️🔗 LangChain](https://python.langchain.com/en/latest/index.html) and state-of-the-art [Large Language Models](https://docs.cohere.com/docs/introduction-to-large-language-models) (LLM) to provide a conversational experience backed by data.\n",
    "\n",
    "> For the latest news on GenAI, please visit the [Generative AI on AWS](https://aws.amazon.com/generative-ai/) landing page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0f79b1-1124-43f7-a659-a6d1c249fa32",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "The diagram below shows the architecture of a GenAI application with a RAG approach:\n",
    "\n",
    "<img src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/05/02/ML-13807-image001-new.png\" width=\"30%\"/>\n",
    "\n",
    "We use an [Amazon Kendra index](https://docs.aws.amazon.com/kendra/latest/dg/hiw-index.html) to hold large quantities of unstructured data from multiple [data sources](https://docs.aws.amazon.com/kendra/latest/dg/hiw-data-source.html):\n",
    "\n",
    "* Wiki pages\n",
    "* [MS SharePoint sites](https://docs.aws.amazon.com/kendra/latest/dg/data-source-sharepoint.html)\n",
    "* Document repositories e.g. [Amazon S3](https://docs.aws.amazon.com/kendra/latest/dg/data-source-s3.html)\n",
    "* &c.\n",
    "\n",
    "Each time the user interacts with the GenAI app, the following will happen:\n",
    "\n",
    "1. The user makes a request to the GenAI app\n",
    "2. The app issues a [search query](https://docs.aws.amazon.com/kendra/latest/dg/searching-example.html) to the Amazon Kendra index based on the user request\n",
    "3. The index returns search results with excerpts of relevant documents from the ingested data\n",
    "4. The app sends the user request along with the data retrieved from the index as context in the LLM prompt\n",
    "5. The LLM returns a succint response to the user request based on the retrieved data\n",
    "6. The response from the LLM is sent back to the user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fceeb54-28ff-446e-9e66-2eb8c6d8464f",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "> **Note:** This notebook was tested with [Amazon SageMaker Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/studio.html) with the [Base Python 3.0 [`sagemaker-base-python-310`] image](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-images.html) on a `ml.t3.medium` (2 vCPU + 4 GiB) instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22974f6-b724-4f28-be12-51eb8fad2344",
   "metadata": {},
   "source": [
    "We will need a Python version compatible with [🦜️🔗 LangChain](https://pypi.org/project/langchain/) (`>=3.8.1, <4.0`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093092c2-be80-4233-ba8e-6e8b6c9bd7d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28631311-8d7a-4ce4-a453-e00e14cda932",
   "metadata": {},
   "source": [
    "**(optional)** [AWS CLI](https://aws.amazon.com/cli/) `v2` to create the Kendra stack\n",
    "\n",
    "> For more information on how to upgrade the AWS CLI, see [Installing or updating the latest version of the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)\n",
    "\n",
    "> Make sure you give enough permissions to the [execution role](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) when running this notebook through Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488dda35-9873-4b2a-b476-0fa2bcf696e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcab366a-8d84-4c85-97b1-878ac574edae",
   "metadata": {},
   "source": [
    "**(optional)** a recent version of the [SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/) (`>=2.154.0`) containing the [SageMaker JumpStart SDK](https://github.com/aws/sagemaker-python-sdk/releases/tag/v2.154.0) to deploy the LLM to a SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5973708-5667-458a-bd7e-90051d10c9ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env PIP_DISABLE_PIP_VERSION_CHECK True\n",
    "%env PIP_ROOT_USER_ACTION ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210f2bc-b3c4-4789-954a-8b7e5e3e3bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install -qU \"sagemaker>=2.154.0\"\n",
    "!python -c \"import sagemaker; print(sagemaker.__version__)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1bf9d7-4f2f-4591-9208-1cf091daa8cc",
   "metadata": {},
   "source": [
    "Edit and run the cell below to skip certain steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b404ed-d4de-4133-aca9-1ae01828db0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext skip_kernel_extension\n",
    "\n",
    "# Whether to skip the Kendra index deployment\n",
    "SKIP_KENDRA_DEPLOYMENT = False\n",
    "\n",
    "# Stack name for the Kendra index deployment\n",
    "KENDRA_STACK_NAME = \"genai-kendra-langchain\"\n",
    "\n",
    "# Whether to skip the quota increase request\n",
    "SKIP_QUOTA_INCREASE = True\n",
    "\n",
    "# Whether Streamlit should be installed\n",
    "SKIP_STREAMLIT_INSTALL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d8512-cd1c-4f74-81fc-4706aaa3a495",
   "metadata": {},
   "source": [
    "### Implement a RAG Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae38fd21-e54d-425c-a836-b0f146ff78ea",
   "metadata": {},
   "source": [
    "Let's start by cloning the [AWS LangChain](https://github.com/aws-samples/amazon-kendra-langchain-extensions) repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac355f7-4550-4b60-90d1-7232f28b63d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/aws-samples/amazon-kendra-langchain-extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b193c61d-1d51-40fb-bc22-fbdcd22d0c50",
   "metadata": {},
   "source": [
    "This repo contains a set of utility classes to work with Langchain incl. a retriever class `KendraIndexRetriever` for working with a Kendra index and sample scripts to execute the Q&A chain for SageMaker, Open AI and Anthropic providers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e61f630-2685-4c51-9955-f344e1b47cdd",
   "metadata": {},
   "source": [
    "**Optional:** Deploy the provided AWS CloudFormation template ([`samples/kendra-docs-index.yaml`](https://github.com/aws-samples/amazon-kendra-langchain-extensions/blob/main/samples/kendra-docs-index.yaml)) to create a new Kendra index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade29089-ea81-4e04-be14-5e4aad4f030b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%skip $SKIP_KENDRA_DEPLOYMENT\n",
    "!aws cloudformation deploy --stack-name $KENDRA_STACK_NAME --template-file \"amazon-kendra-langchain-extensions/samples/kendra-docs-index.yaml\" --capabilities CAPABILITY_NAMED_IAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4abc48-f25b-4805-bd5e-904ef231f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $SKIP_KENDRA_DEPLOYMENT\n",
    "!aws cloudformation describe-stacks --stack-name $KENDRA_STACK_NAME --query 'Stacks[0].Outputs[?OutputKey==`KendraIndexID`].OutputValue' --output text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b7ee8a-b1d1-4747-a90a-5b2b3c1d8dbe",
   "metadata": {},
   "source": [
    "**Optional:** For a better experience, request a larger document excerpt to be returned via [AWS Service Quotas](https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230aaa4e-2875-41c7-a56f-fc1db5b3e9ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%skip $SKIP_QUOTA_INCREASE\n",
    "# Request a quota increase for the maximum number of characters displayed in the Document Excerpt of a Document type result in the Query API\n",
    "# https://docs.aws.amazon.com/kendra/latest/APIReference/API_Query.html\n",
    "!aws service-quotas request-service-quota-increase --service-code kendra --quota-code \"L-196E775D\" --desired-value 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e570923b-efcc-4e3f-ab88-3afab8f17b79",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Optional:** Install [Streamlit](https://streamlit.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35987475-d40a-4720-8e32-096bc8286047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%skip $SKIP_STREAMLIT_INSTALL\n",
    "\n",
    "# Install streamlit\n",
    "# https://docs.streamlit.io/library/get-started/installation\n",
    "!{sys.executable} -m pip install -qU streamlit\n",
    "\n",
    "# Debug installation\n",
    "# https://docs.streamlit.io/knowledge-base/using-streamlit/sanity-checks\n",
    "!streamlit version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f882417-9345-4483-a7fd-e945f319b152",
   "metadata": {
    "tags": []
   },
   "source": [
    "Install [LangChain 🦜️🔗](https://github.com/hwchase17/langchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3aea9-5632-442e-8a41-441dd3fa7b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install LangChain\n",
    "# https://python.langchain.com/en/latest/getting_started/getting_started.html\n",
    "!{sys.executable} -m pip install -qU \"langchain==0.0.137\"\n",
    "\n",
    "# Debug installation\n",
    "!python -c \"import langchain; print(langchain.__version__)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07479ad8-f3c9-4510-8f86-7567bd6f6251",
   "metadata": {},
   "source": [
    "Next, we need an LLM to process requests. \n",
    "\n",
    "Models like [Flan-T5-XL](https://huggingface.co/google/flan-t5-xl) and [Flan-T5-XXL](https://huggingface.co/google/flan-t5-xxl) can be deployed in just a few lines of code via [Amazon SageMaker JumpStart](https://aws.amazon.com/sagemaker/jumpstart/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064441d-6db4-43a5-a518-a187a08740c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "# Select model\n",
    "# https://aws.amazon.com/sagemaker/jumpstart/getting-started\n",
    "model_id = str(input(\"Model ID:\") or \"huggingface-text2text-flan-t5-xl\")\n",
    "\n",
    "# Deploy model\n",
    "model = JumpStartModel(model_id=model_id)\n",
    "predictor = model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9492a301-7299-46ca-a27f-08cf0bba3e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test model\n",
    "predictor.predict(\"Hey there! How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ef0c04-10e9-41d9-8a20-993f02f91901",
   "metadata": {},
   "source": [
    "**Optional:** If you want to work with [Anthropic's `Claude-V1`](https://www.anthropic.com/index/introducing-claude) or [OpenAI's `da-vinci-003`](da-vinci-003), get an API key and run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d958fa-4ed9-4e1d-a1cf-c8ba04b9b830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "\"\"\"\n",
    "OpenAI\n",
    "https://python.langchain.com/en/latest/modules/models/llms/integrations/openai.html\n",
    "\"\"\"\n",
    "\n",
    "# Get an API key from\n",
    "# https://platform.openai.com/account/api-keys\n",
    "OPENAI_API_KEY = getpass(\"OPENAI_API_KEY:\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "\"\"\"\n",
    "Anthropic\n",
    "https://python.langchain.com/en/latest/modules/models/chat/integrations/anthropic.html\n",
    "\"\"\"\n",
    "\n",
    "# Get an API key from\n",
    "# https://www.anthropic.com/product\n",
    "ANTHROPIC_API_KEY = getpass(\"ANTHROPIC_API_KEY:\")\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0631867b-cfba-457e-a5bd-f09ba60f969f",
   "metadata": {},
   "source": [
    "Install the `KendraIndexRetriever` interface and sample applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46de18-8599-4300-a9d6-b88f19c316c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install classes\n",
    "!{sys.executable} -m pip install -qU ./amazon-kendra-langchain-extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5825a3-9fe0-4ca6-a1b3-bc4ed39305a7",
   "metadata": {},
   "source": [
    "Before running the sample application, we need to set up the environment variables with the Amazon Kendra index details and the SageMaker endpoints for the `FLAN-T5-*` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc6cc1c-a0ce-417c-a92f-bd1344132025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Set Kendra index ID\n",
    "os.environ['KENDRA_INDEX_ID'] = input('KENDRA_INDEX_ID:')\n",
    "\n",
    "# Set endpoint name\n",
    "# https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart-foundation-models/text2text-generation-flan-t5.ipynb\n",
    "if re.search(\"flan-t5-xl\", model_id):\n",
    "    os.environ['FLAN_XL_ENDPOINT'] = predictor.endpoint_name\n",
    "elif re.search(\"flan-t5-xxl\", model_id):\n",
    "    os.environ['FLAN_XXL_ENDPOINT'] = predictor.endpoint_name\n",
    "elif \"OPENAI_API_KEY\" in os.environ or \"ANTHROPIC_API_KEY\" in os.environ:\n",
    "    print(\"Using external API key\")\n",
    "else:\n",
    "    print(\"⚠️ The SageMaker Endpoint environment variable is not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a8fdc8-dd0c-4a9d-bb5c-b812221313e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now, we can finally start the application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30fb0e2-f2af-4f5a-b8a0-d0d706b5d984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "!cd amazon-kendra-langchain-extensions/samples && python kendra_chat_flan_xl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb063d0f-515e-4f0d-97b2-95c65ca1ea01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Streamlit\n",
    "!cd amazon-kendra-langchain-extensions/samples && streamlit run app.py flanxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3000db-84b3-46fe-b6bc-a354ed8dcd18",
   "metadata": {},
   "source": [
    "> **Note:** As of May 2023, Amazon SageMaker Studio doesn't allow apps to run through Jupyter Server Proxy on a Kernel Gateway. The best option is to use the [SageMaker SSH Helper](https://github.com/aws-samples/sagemaker-ssh-helper) library to do port forwarding to `server.port` (defaults to `8501`) cf. [Local IDE integration with SageMaker Studio over SSH for PyCharm / VSCode](https://github.com/aws-samples/sagemaker-ssh-helper#local-ide-integration-with-sagemaker-studio-over-ssh-for-pycharm--vscode) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a59dbc-55ba-4a15-b0f1-3e2d764d7fc5",
   "metadata": {},
   "source": [
    "<img src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/04/25/ML-13807-image005.jpg\" width=\"30%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5299dc29-fa23-407e-aba0-aea056979246",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "Delete SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2233be-e5e9-4c63-a694-605bf08bf46c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47d328a-e236-4b6d-8462-59a38316f347",
   "metadata": {},
   "source": [
    "Delete Kendra stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842c617-b74e-46b1-b7c7-79f2397657da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%skip $SKIP_KENDRA_DEPLOYMENT\n",
    "!aws cloudformation delete-stack --stack-name $KENDRA_STACK_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4feb917-1844-42bf-ba63-1f090173b389",
   "metadata": {},
   "source": [
    "### References 📚\n",
    "\n",
    "* AWS ML Blog: [Quickly build high-accuracy Generative AI applications on enterprise data using Amazon Kendra, LangChain, and large language models](https://aws.amazon.com/blogs/machine-learning/quickly-build-high-accuracy-generative-ai-applications-on-enterprise-data-using-amazon-kendra-langchain-and-large-language-models/)\n",
    "* AWS ML Blog: [Question answering using Retrieval Augmented Generation with foundation models in Amazon SageMaker JumpStart](https://aws.amazon.com/blogs/machine-learning/question-answering-using-retrieval-augmented-generation-with-foundation-models-in-amazon-sagemaker-jumpstart/)\n",
    "* AWS ML Blog: [Dive deep into Amazon SageMaker Studio Notebooks architecture](https://aws.amazon.com/blogs/machine-learning/dive-deep-into-amazon-sagemaker-studio-notebook-architecture/)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Base Python 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-base-python-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
